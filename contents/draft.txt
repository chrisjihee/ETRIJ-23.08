# Introduction {#sec:intro}

Korean morphological analysis is the process of determining parts of
speech by identifying morphemes, which are the smallest units of
linguistic expression with independent meanings in a sentence. In an
isolating language, such as English, this identification can be achieved
relatively easily by tagging parts of speech sequentially. However, in
Korean, the nature of the agglutinative language requires separating
endings or postpositions and restoring inflections to their original
form. In addition, because the basic input of other Korean analysis
tasks is often a separate morpheme, the accuracy of the morphological
analysis significantly affects the performance of Korean analysis.
Modern high-performance deep learning methods in natural language
processing (NLP) use a tokenization process that breaks the text into
smaller units and converts each token into a vector as an input to the
computational model [@Mikolov2013]. Here, the token unit is mainly a
subword unit, and to reflect the characteristics of a Korean subword,
tokenization with separate morphemes is attempted in
advance [@SongHJ2021]. Using the results of the morphological analysis
for this tokenization process improves the overall performance of the
analysis by reflecting the semantic units of Korean. This requires a
highly accurate and fast morphological analyzer.

Various approaches have been proposed for morphological analysis, which
is crucial in Korean language
analysis [@KwonHC1991; @LeeDG2009; @ShimKS2011; @LeeJS2011; @ShinJC2012; @LeeCK2013; @NaSH2014; @NaSH2015; @HwangHS2016; @KimHM2016; @ChungES2016; @LeeCH2016; @Li2017; @NaSH2018; @KimSW2018; @ChoiYS2018; @MinJW2018; @MinJW2019; @KimHM2019; @SongHJ2019; @MinJW2020; @SongHJ2020; @ChoiYS2020; @HwangHS2020; @KimHJ2021; @YounJY2021; @MinJW2022; @KimJM2022; @ShinHJ2023].
In general, when people understand speech or written text, they attempt
to make sense of it using vocabulary and concepts that they are familiar
with. While there are approaches to use rules or dictionaries to reflect
this understanding [@KwonHC1991], it becomes difficult to build and
maintain a dictionary for the vocabulary that appears in each text.
Therefore, methods for tagging syllable units without a dictionary have
been proposed [@ShimKS2011; @LeeCK2013; @LeeCH2016; @KimHM2016] and
studies have been conducted to improve them
 [@KimSW2018; @ChoiYS2018; @KimHM2019; @MinJW2019; @SongHJ2019; @SongHJ2020; @YounJY2021; @ShinHJ2023].
From a mechanical perspective, syllable-by-syllable morphological
analysis can be performed either by tagging syllable-by-syllable and
then applying a base-form restoration
dictionary [@ShimKS2011; @LeeCH2016], or by tagging syllable-by-syllable
with the base form already restored [@YounJY2021]. However,
syllable-by-syllable morphological analysis has limitations, in that it
is difficult to accurately identify morpheme boundaries and learn
long-term contextual information as the length of the sequence
increases. In this study, the former is referred to as dictionary-based
morphological analysis and the latter as syllable-unit morphological
analysis. Both methods are trained on a manually labeled corpus and
cannot accurately analyze new syllable combinations or morphemes that do
not appear in the training corpus. Recently, with the development of the
Internet and the spread of open sources as well as open data, web texts,
corpora, language resources, and knowledge shared by different people
have accumulated significantly. The reduced cost of building and
maintaining a dictionary provides a significant opportunity to overcome
the limitations of dictionary-based methods.

Against this background, this study considers how the dictionary-based
morphological analysis method used by MeCab [@MeCab], an open software
for Korean and Japanese morphological analysis in tokenizers, which is
an essential preprocessing tool for deep learning, can be effectively
improved, and a method is proposed. The dictionary-based morphological
analysis method [@Kudo2004; @NaSH2014; @NaSH2015; @NaSH2018] trained by
the CRF (Conditional Random Fields) method [@Lafferty2001] lists the
candidate morphemes in the dictionary from a given sentence to form a
lattice structure connected by a directed graph and determines the
optimal morphological analysis path within it. The process of
determining the optimal path in the lattice uses the Viterbi
algorithm [@Viterbi1967], which determines the path that minimizes the
cost of each morpheme node and the sum of the neighborhood costs of two
consecutive morphemes. The main types of errors in these
dictionary-based morphological analysis methods occur when new words
that are not in the dictionary are used in a sentence, or when the
optimal path calculation selects the incorrect result owing to bias. For
example, it may be cost-effective to select one long morpheme than
several short morphemes, but this may often lead to an incorrect
analysis. The main motivation for this study was that the path that
minimizes the costs for the nodes and links may not be the optimal path.

To identify cases in which a suboptimal solution is actually the best
solution according to the best path calculation, we modified the best
path calculation method to generate suboptimal analysis results and
verified the extent to which they are correct. Although there are
numerous different approaches to select the next-best path, we used the
method of replacing a morpheme node on the optimal path with a
lower-ranked node. As shown in
Table [\[tab:maximum-performance\]](#tab:maximum-performance){reference-type="ref"
reference="tab:maximum-performance"}, we confirm the extent to which the
analysis performance can be improved by replacing the optimal path with
a lower-ranked node. We can consider the problem of finding the correct
answer among the generated sub-optimals, similar to the problem of
re-ranking search results in information retrieval [@BaeYJ2021]. In
 [@ChoiYS2018], the N-best analysis results generated by the seq2seq
model were re-ranked based on a convolutional neural network to improve
the performance. In this study, re-ranking was performed using two BERT
models of different types and forms, as proposed in  [@Nogueira2019].
Experimental results show that first-stage re-ranking improves the
performance by over 20% over previously written and spoken models, and
second-stage re-ranking with a different type of input and a different
type of pre-trained model further improves the performance by more than
30% over previously written and spoken models.

With this method, the performance of the dictionary-based morphological
analysis method could be further improved; however, the overall analysis
time increased when the morphological analysis system was configured,
including the re-ranking model itself. However, it is feasible to use
the results of multiple reranked morpheme analyses to update the
connection costs between morphemes in a dictionary, similar to the
backpropagation process in a typical neural network. It is also expected
that the morphological analysis system with improved connection costs
will be able to generate better re-ranking candidates, which will
further improve performance by doing so iteratively. Further research is
required in the future. In this study, only performance improvement
using the second-stage re-ranking was covered as the scope of the study.
The main contributions of this study are as follows.

1.  **Further improvement of dictionary-based morphological analysis
    method using suboptimal analysis results**: We explore the
    possibility of performance improvement by introducing a method to
    replace the optimal path with a suboptimal node and propose a method
    to effectively improve the dictionary-based morphological analysis
    method through deep learning.

2.  **Extending the performance improvement by introducing a two-stage
    re-ranking model**: To improve the performance of dictionary-based
    analysis by re-ranking the morphological analysis results, we
    propose extending the performance improvement using different BERT
    models to perform two rounds of re-ranking.

3.  **A method for updating connection costs in the dictionary and
    suggestions for future research**: We propose a new method for
    updating dictionary connection costs based on re-ranked
    morphological analysis results. We also outline directions for
    future research, suggesting potential improvements.

These contributions provide important insights into the performance
improvement of Korean morphological analysis and the direction of future
research, and will serve as a useful reference for future researchers.

The remainder of this paper is organized as follows. In Section
 [2](#sec:morphological-analysis-model){reference-type="ref"
reference="sec:morphological-analysis-model"}, we discuss configuring
and training a dictionary-based morphological analysis system. In
Section  [3](#sec:reranking-model){reference-type="ref"
reference="sec:reranking-model"}, we discuss the generation of secondary
results of morphological analysis, produce re-ranking data, and propose
a method for training a two-stage re-ranking model. In Section
 [4](#sec:results){reference-type="ref" reference="sec:results"}, we
discuss the results of the performance improvement using the
morphological analysis and re-ranking models. In Section
 [5](#sec:related-work){reference-type="ref"
reference="sec:related-work"}, we introduce previous research cases
related to this study. Finally, in Section
 [6](#sec:conclusion){reference-type="ref" reference="sec:conclusion"},
we conclude the study and discuss its limitations and directions for
future research.

# Morphological Analysis Model {#sec:morphological-analysis-model}

## Korean Morphological Analysis Corpora {#subsec:korean-morphological-analysis-corpora}

In this study, we used three major corpora to train and evaluate Korean
morphological analysis models, each of which has unique characteristics
and serves different research purposes.

**Sejong Corpus**: Originating from the 21st Century Sejong Project,
this corpus consists of a total of 15 million eojeols, including the raw
untagged corpus, and forms the backbone of Korean morphological analysis
research [@ChoeMW2008]. It provides a wide variety of linguistic
patterns and structures that are important for baseline training and
validation of morphological analysis models, and has been used for
performance comparisons with other studies. In most of the previous
studies, only a part of the Sejong corpus was used for experiments, and
in this study, we used the dataset provided by the researchers in
 [@NaSH2014].

**UCorpus (University of Ulsan Corpus)** [@UCorpusHG]: This is an
extension of the Sejong corpus, which is constantly being maintained and
added to by the University of Ulsan, significantly increasing its volume
to 63 million eojeols and testing the adaptability and accuracy of the
model to a wider range of data. The expansion includes corrections to
previously raised errors  [@KimIH2010] and a number of annotation
outputs for new data, providing a substantial basis for comprehensive
linguistic analysis.

**Everyone's Corpus** [@EveryoneCorpus]: Launched by the National
Institute of the Korean Language in 2020, the Everybody's Corpus
enriches the data landscape with web texts and spoken language materials
that reflect contemporary language use [@KimIH2019]. This modern corpus
reflects the dynamic evolution of the Korean language and is playing a
pivotal role in improving models for capturing the nuances of current
Korean usage.

Table [\[tab:data-statistics\]](#tab:data-statistics){reference-type="ref"
reference="tab:data-statistics"} details the specific number of
sentences and words in each corpus, and the data subsets extracted for
model training and evaluation. During the training data conversion
process, we first removed duplicate sentences and excluded sentences
with annotation errors or other problems. We can see that many duplicate
sentences occur, especially in spoken language.

## Training Example Transformation {#subsec:training-example-transformation}

To train a dictionary-based morpheme analysis model effectively, the
morpheme-tagged corpus, typically represented in lemma form, must be
transformed to include the boundary information between morphemes in its
surface form. Crucial to this transformation is string alignment, a
process that accounts for the discrepancies between lemma forms and
surface forms in the Korean morphological analysis corpus.

In this study, string alignment was performed using the Smith--Waterman
algorithm, which uses a scoring matrix based on the similarity of the
grapheme unit of Korean letters for each word pair (as shown in
Figure [\[fig:sample\]](#fig:sample){reference-type="ref"
reference="fig:sample"}). Each aligned sentence containing a morpheme
tag was converted into a training sample tailored for dictionary-based
morphological analysis.

The resulting table in
Figure [\[fig:sample\]](#fig:sample){reference-type="ref"
reference="fig:sample"} illustrates this process. Each row acts as a
lexical unit. The first four columns contribute to feature generation,
whereas the last four columns facilitate post-lemmatization. Using the
morphological corpus above, a large number of training samples can be
generated according to the process shown in
Figure [\[fig:sample\]](#fig:sample){reference-type="ref"
reference="fig:sample"}. With the exception of the evaluation samples,
the remaining sentences were used to train the dictionary-based
morphological analysis model using the CRF algorithm. The output of this
training allowed the calculation of the costs associated with each
morpheme node and the linking of two consecutive morphemes. This, in
turn, allowed the discovery of an optimal path using the Viterbi
algorithm.

## Lattice Construction and Decoding {#subsec:lattice-construction-and-decoding}

Figure [\[fig:lattice\]](#fig:lattice){reference-type="ref"
reference="fig:lattice"} presents a snapshot of the lattice structure,
which is an integral part of the morphological analysis. (1) shows a
fragment of the lattice structure formed when the example sentence in
Figure [\[fig:sample\]](#fig:sample){reference-type="ref"
reference="fig:sample"} is entered. (2) shows the optimal path
determined using the Viterbi algorithm.

However, the path inferred by the trained model may differ from the
correct solution constructed by humans. The nodes marked with stars in
(1) represent correct nodes. The upper-left number of each node
indicates the ranking of the nodes accessible at each decoding point.
The choices made at certain moments deviate from the correct solution.
To improve analytical performance, mechanisms to correct these
discrepancies must developed.

# Re-ranking Model {#sec:reranking-model}

## Motivation and Background {#subsec:motivation-and-background}

Although dictionary-based morphological analysis offers significant
advances, its optimal paths occasionally diverge from the correct
solutions that humans understand. This divergence underscores the need
for a model that reevaluates these primary results and reorients them to
achieve higher accuracy. This method, called re-ranking, involves
generating multiple analyses of an input and then reordering them based
on a new set of criteria or models, thereby improving the overall
quality of the results.

## Secondary Path Generation {#subsec:secondary-path-generation}

Before reranking begins, multiple analyses, typically referred to as the
N-best paths, of the input sentence are generated. This involves
extracting the top N atoms from the lattice structure. In this study, a
novel approach is introduced to generate secondary paths, as shown in
(3) of Figure [\[fig:lattice\]](#fig:lattice){reference-type="ref"
reference="fig:lattice"}, by selecting the second-best node rather than
each best node constituting the path from the best-path result. Some of
these secondary paths provided alternatives that reconciled incorrect
with correct answers. Similarly, paths modified by favoring the
third-best node were called tertiary paths, and this naming convention
was continued for subsequent paths. In our preliminary test, the
secondary paths, including the optimal and suboptimal paths, were shown
to cover the majority of the correct morphological analyses as measured
through human evaluations. (Refer to
Table [\[tab:maximum-performance\]](#tab:maximum-performance){reference-type="ref"
reference="tab:maximum-performance"}).

## BERT-based Re-ranking {#subsec:bert-based-reranking}

Bidirectional Encoder Representations from Transformers (BERT)
models [@Devlin2019] have revolutionized many natural language
processing tasks by understanding the context in which words appear in
text. In this study, we attempt to leverage the power of BERT to reorder
the generated secondary paths. We labeled the generated secondary paths
with scores related to the morphological analysis performance to
fine-tune a pre-trained BERT model specialized for Koreans with excess
amount Korean text. After pre-testing several scoring methods on a
modest scale, we found that using scores based on the degree of error
rather than scores based on accuracy by widen the gap between correct
and incorrect answers is effective for learning.

Once the BERT model is fine-tuned and trained for the re-ranking task,
it can predict a re-ranking score for each path in the secondary path
list. This implies that considering the context, morphological
organization, and other essential linguistic features of the path, the
model assigns a score to each path. The paths were then re-ranked
according to this score, and the path with the highest score was
selected for the best morphological analysis.

## Two-stage Re-ranking {#subsec:two-stage-reranking}

Given the complexity of the Korean language, a single re-ranking step
does not constantly yield accurate results. Therefore, we propose a
two-step re-ranking approach as described in  [@Nogueira2019].

In the first step, we re-rank the secondary paths generated using the
BERT model, as described in Section
 [3.3](#subsec:bert-based-reranking){reference-type="ref"
reference="subsec:bert-based-reranking"}. In the second step, we
introduced another BERT variant that was optimized for a different set
of linguistic features or trained on a different dataset. This allowed
us to perform a fine-grained re-evaluation, further refine the list, and
push more contextually accurate paths to the top.

As shown in Figure [\[fig:ranking\]](#fig:ranking){reference-type="ref"
reference="fig:ranking"}, for a two-stage reranking model, the first
stage performs the first re-ranking, taking as input a secondary path in
morphologically tagged lemma form. It then performs a second re-ranking,
again taking as input the path re-ranked in stage 1 and the original
input sentence. This was conducted to improve effectiveness, as it was
ineffective given the same type of input.

# Experimental Results {#sec:results}

We evaluated the performance of the proposed deep learning-integrated
dictionary-based morphological analysis method. This section presents
the results of the experimental evaluation considering the improvements
over conventional methods and the effectiveness of our re-ranking model.

## Setup and Data {#subsec:setup-and-data}

For our experiments, we used the Sejong corpus (versions used in
 [@NaSH2014; @NaSH2015; @NaSH2018; @SongHJ2019; @SongHJ2020]),
UCorpus[@UCorpusHG], and Everyone's Corpus[@EveryoneCorpus]. For
comparison with previous studies, the Sejong corpus was trained using a
single model without separation. The UCorpus and Everyone's Corpus
provided a separate spoken corpus with drama scripts and broadcast
dialogues, while UCorpus separated documents that were considered to be
close to spoken language and further organized them into a semi-spoken
corpus. Because UCorpus and Everyone's Corpus have synergistic effects
when trained concurrently, we trained the models separately for written
and spoken language rather than separating them by source. The
statistics of the full data for the three types of models are presented
in
Table [\[tab:data-statistics\]](#tab:data-statistics){reference-type="ref"
reference="tab:data-statistics"}. Because of the large volume of
UCorpus, we randomly selected some of them to train the actual model.

We transformed this organized morphological corpus using the
training-example transformation process described in Section
 [2.2](#subsec:training-example-transformation){reference-type="ref"
reference="subsec:training-example-transformation"} to generate samples
for training the dictionary-based morphological analysis model.

## Evaluation Metrics {#subsec:evaluation-metrics}

To measure the accuracy of the morphological analysis model, correctness
of the N-best path, and ranking accuracy of the reranking model, we used
the eojeol accuracy and morpheme F1 scores as evaluation metrics. To
verify that they produced the correct morphological analysis results, we
measured the degree of agreement with human annotations on the corpus.
However, owing to the slightly different criteria and styles of the
annotators who labeled the different types of corpora, including the
comparison with the MeCab-ko system, the following adjustments were
made:

-   Sentences containing unanalyzable tags (NF, NA, and NV) were
    excluded from both training and evaluation.

-   As for the tagsets, we excluded three unanalyzable tags from the 45
    Sejong tagsets and used 42 tagsets.

-   Each tag output by the MeCab-ko system was converted to the
    corresponding tag in the Sejong tagset.

-   Chinese characters were converted to Chinese character tags (SH)
    even if they were semantically used as nouns, and consecutive
    Chinese characters were converted to a single morpheme.

-   Similarly, symbol, numeral, ending, and postposition in the same tag
    were converted to a single morpheme, and decimal expressions were
    treated as a single morpheme, including the midpoint and the numbers
    before and after.

-   If the first lemma letter of the ending is '\[eo\]', '\[yeo\]', or
    '\[ah\]', it is unified as '\[eo\]', and if it is '\[eot\]',
    '\[yeot\]', or '\[ass\]', it is unified as '\[eot\]'.

-   Root tags (XR) used alone without affixes were replaced with common
    nouns (NNG) because they are mainly used in the Sejong corpus only.

-   As mentioned in  [@KimIH2010], connective endings (EC) and
    sentence-closing endings (EF) are not clearly defined in the tagging
    guidelines, and there are cases where they are used interchangeably
    in the corpus, to ensure that we evaluated them without
    distinguishing them.

-   The distinction between '\[geot\]' and '\[geo\]' is unclear in the
    tagging guidelines, and there are cases where they are used
    interchangeably in the corpus, hence, we did not distinguish between
    them.

-   Compound words can be interpreted as a single morpheme or as a
    combination of two or more morphemes or affixes, hence, we evaluated
    them without distinguishing between them.

-   Proper nouns can also be interpreted as common nouns depending on
    the point of view or perspective. Human annotators have slightly
    different standards, and thus they were also evaluated without
    distinguishing the nouns.

## Basic Performance {#subsec:basic-performance}

First, we compared the initial results of the dictionary-based
morphological analysis model trained using the method described in
Section  [2](#sec:morphological-analysis-model){reference-type="ref"
reference="sec:morphological-analysis-model"} with those of MeCab and
syllable-based morphological analysis systems (refer to
Table [\[tab:performance-without-reranking\]](#tab:performance-without-reranking){reference-type="ref"
reference="tab:performance-without-reranking"}). The results show that
the dictionary-based method implemented is superior to the existing
MeCab system, but it differs from human evaluations owing to the
limitations mentioned above, and it does not reach the performance of
existing syllable-based morphological analysis systems. We also found
that the compatibility between the Sejong corpus and other corpora is
poor, as the model trained on the Sejong corpus has guaranteed
performance when evaluated on the Sejong corpus, and some performance
degradation occurs on other corpora.

## Re-ranking Performance {#subsec:reranking-performance}

Upon integrating the BERT-based re-ranking model, we observed
substantial performance enhancement.
Table [\[tab:performance-with-reranking\]](#tab:performance-with-reranking){reference-type="ref"
reference="tab:performance-with-reranking"} shows that the re-ranking
model identified a better path in a significant proportion of cases. The
first-stage re-ranking exhibited a performance improvement of over 20%
compared with traditional models. The subsequent re-ranking, leveraging
a distinct type of input and a different pre-trained model, further
augmented the performance by more than 30%.

Next, we performed the BERT-based re-ranking described in Section
 [3](#sec:reranking-model){reference-type="ref"
reference="sec:reranking-model"} and compared its performances. Three
pre-trained language models, KPF-BERT, ETRI-ELECTRA, and ETRI-RoBERTa,
which are known to perform well in other Korean language understanding
tasks, were used to fine-tune the re-ranking model. KPF-BERT received
Korean sentences as input, ETRI-ELECTRA received morphologically tagged
sentences as input, and ETRI-RoBERTa receives morpheme-separated
sentences as input. For KPF-BERT and ETRI-RoBERTa, there may be problems
with model learning because of the separation of morpheme tags into
letter units during the tokenization process when the morpheme analysis
results were received as input and re-ranked, hence, the morpheme tags
of the mid-level classification unit were added as new tokens, and then
training was performed. As shown in
Figure [\[fig:ranking\]](#fig:ranking){reference-type="ref"
reference="fig:ranking"}, for these three types of pre-trained language
models, we first performed training with a re-ranking model using only
the morphological analysis results and then performed training with a
second re-ranking model using the top five morphological analysis
results from the first re-ranking results along with the input sentences
for other types of pre-trained language models. Preliminary tests
indicate that using the same type of model or input results in a nearly
identical retrained model, with no further improvement in performance.

The sentences used for training the re-ranking model were selected from
those used for training the dictionary-based morphological analysis
model: 190,000 sentences from the Sejong corpus, 240,000 sentences from
the written language of the combined UCorpus and Everyone's corpus, and
360,000 sentences from the spoken language of the combined UCorpus and
Everyone's corpus. For a large number of sentences, we adopted a
floating-point 16-bit technique while using four GPUs for distributed
training and significantly reduced the time required for training. In
addition, the minibatch size was 120 with a maximum sequence length of
384 because the first re-ranking uses only the morphological analysis
results as input. The minibatch size was 40 with a maximum sequence
length of 512 because the original input sentences were given as input
along with the first morphological analysis results. The learning rate
was set to $2 \times 10^{-5}$ and AdamW is used as the optimization
algorithm.

Table [\[tab:performance-with-reranking\]](#tab:performance-with-reranking){reference-type="ref"
reference="tab:performance-with-reranking"} shows that incorporating the
re-ranking model significantly improves the performance compared with no
re-ranking. The error reduction rate (ERR) of the performance change
from the existing model on eojeol accuracy is shown as 29%, 27%, and 20%
for the Sejong corpus, combined written corpus, and combined spoken
corpus, respectively, with the first round of re-ranking, and the second
round of re-ranking improved the performance by increasing the rate to
34%, 34%, and 32%, respectively. These performance improvements
demonstrate that the dictionary-based morphological analysis model
outperforms traditional syllable-based morphological analysis systems,
including numerous pre- and post-processing rules and dictionaries.

## Comparison to Other Studies {#subsec:comparison-to-other-studies}

We found that the proposed transformer-based re-ranking technique
consistently improved the results of the existing morphological analysis
models. These results confirm that it opens up new possibilities by
further improving the results of existing traditional machine-learning
models in the field of Korean morphological analysis. Finally, because
the major related studies proposed in the literature were mostly
conducted on the Sejong corpus, we compared the performance improvement
of the Sejong corpus with the results of previous studies. Although it
is difficult to make a direct comparison because of slight differences
in implementation conditions and evaluation criteria. The proposed
dictionary-based morphological analysis model is not up to the latest
research results; however, by incorporating a re-ranking model, it can
secure a performance that is comparable to existing research.

The entire morphological analysis model, including the re-ranking model,
is not suitable for real-time processing. However, it is expected that
by reflecting the cases whose ranks are changed through the re-ranking
model as feedback to the dictionary-based morphological analysis model,
it will be feasible to obtain near-improved morphological analysis
performance. The improved dictionary-based morphological analysis model
can then be used as input to the re-ranking model; therefore, it is
expected that a gradually improvement in morphological analysis model
can be obtained through this iterative feedback loop.

# Related Work {#sec:related-work}

Korean morphological analyses have seen an influx of various
methodologies in recent
years [@KwonHC1991; @LeeDG2009; @ShimKS2011; @LeeJS2011; @ShinJC2012; @LeeCK2013; @NaSH2014; @NaSH2015; @HwangHS2016; @KimHM2016; @ChungES2016; @LeeCH2016; @Li2017; @NaSH2018; @KimSW2018; @ChoiYS2018; @MinJW2018; @MinJW2019; @KimHM2019; @SongHJ2019; @MinJW2020; @SongHJ2020; @ChoiYS2020; @HwangHS2020; @KimHJ2021; @YounJY2021; @MinJW2022; @KimJM2022; @ShinHJ2023].
The nature of the Korean language, being agglutinative, introduces
challenges that have propelled researchers to develop inventive
solutions, many of which have laid the groundwork for future research.
Table [1](#tab:overview-of-recent-korean-morphological-analysis-methods){reference-type="ref"
reference="tab:overview-of-recent-korean-morphological-analysis-methods"}
provides a concise comparison of the methodologies and key concepts of
key studies that are directly or indirectly related to this research,
giving a brief overview of the different methods of morphological
analysis.

::: {#tab:overview-of-recent-korean-morphological-analysis-methods}
  **Authors**                         **Methodology**                                                                                                    **Key Concepts**
  ----------------------------------- ------------------------------------------------------------------------------------------------------------------ -----------------------------------------------------------------------------------------
  Na et al., 2014 [@NaSH2014]         Lattice-based discriminative approach creating a morpheme lattice for POS tagging and morphological analysis       Lattice-based analysis, morpheme segmentation, structured classification
  Na and Kim, 2018 [@NaSH2018]        Phrase-based model for morphological analysis integrating phrases with CRFs                                        Phrase-based modeling, CRFs, discriminative modeling
  Shim, 2011 [@ShimKS2011]            Syllable-based POS tagging method avoiding morphological analysis by employing CRF models                          Syllable-based POS tagging, CRF models, lexical and contextual probabilities
  Lee, 2013 [@LeeCK2013]              Joint model using structural SVM for concurrent word spacing and POS tagging                                       Joint modeling, word spacing, POS tagging, structural SVM, error propagation
  Lee et al., 2016 [@LeeCH2016]       Hybrid algorithm combining machine learning with a pre-analyzed dictionary for syllable-based POS tagging          Hybrid algorithm, syllable-based POS tagging, machine learning, CRF
  Kim et al., 2016 [@KimHM2016]       Method utilizing Bi-LSTM-CRF for POS tagging with input based on syllable distribution patterns                    Syllable-based POS tagging, bi-directional LSTM, CRFs, POS distribution vectors
  Li et al., 2017 [@Li2017]           End-to-end sequence-to-sequence model with convolutional features for morphological analysis and POS tagging       Sequence-to-sequence model, convolutional features, morphological analysis, POS tagging
  Kim and Choi, 2018 [@KimSW2018]     Integrated model using Bi-LSTM-CRF for simultaneous word spacing and POS tagging                                   Bidirectional LSTM, CRF, word spacing, POS tagging, syllable-based analysis
  Choi and Lee, 2018 [@ChoiYS2018]    Reranking model post-processing seq2seq outputs with morpheme-unit embedding and n-grams to reorder results        Seq2seq model, reranking, morpheme-unit embedding, beam search, n-grams
  Min et al., 2019 [@MinJW2019]       Neural transition-based model for end-to-end morpheme segmentation and POS tagging                                 Neural transition-based learning, end-to-end model, morpheme segmentation, POS tagging
  Kim et al., 2019 [@KimHM2019]       Syllable distribution pattern utilization with Bi-LSTM-CRF for morphological analysis and POS tagging              Syllable distribution patterns, Bi-LSTM-CRF, morphological analysis, POS tagging
  Song and Park, 2019 [@SongHJ2019]   Tied sequence-to-sequence multi-task model for morpheme processing and POS tagging                                 Multi-task learning, POS tagging, Morpheme generation, Sequence-to-sequence model
  Song and Park, 2020 [@SongHJ2020]   Two-step POS tagging using an encoder-decoder architecture for morpheme generation followed by sequence labeling   POS Tagging, Morpheme Generation, Encoder-Decoder Architecture, Sequence Labeling
  Youn and Lee, 2021 [@YounJY2021]    Two-step deep learning-based pipeline model for morpheme restoration and POS tagging with BERT                     Deep Learning, Sequence-to-Sequence, BERT, Morpheme Restoration, POS Tagging
  Shin and Lee, 2023 [@ShinHJ2023]    Syllable-Based Multi-POSMORPH Annotation approach                                                                  Syllable distribution patterns, Multi-POSMORPH tags, Transformer encoder, BiLSTM

  : Overview of Recent Korean Morphological Analysis Methods
:::

## Traditional Dictionary-based Approaches {#subsec:traditional-dictionary-based-approaches}

The earliest attempts at Korean morphological analysis relied heavily on
rule- and dictionary-based methods [@KwonHC1991]. These methodologies
employ predefined sets of linguistic rules or large dictionaries to
detect morphemes and determine parts of speech. One of the most
significant advantages of this approach is its deterministic nature,
which can lead to high accuracy when the input text closely adheres to
the rules or dictionaries used. However, it is challenging to scale and
update them, particularly with the constant evolution of language and
the emergence of new words. The dynamic nature of language, particularly
in the Internet age, has made the maintenance of comprehensive
dictionaries labor-intensive.

## Syllable-unit Morphological Analysis {#subsec:syllable-unit-morphological-analysis}

To overcome the limitations of dictionary dependence,
syllable-by-syllable morphological analysis has emerged as an
alternative [@ShimKS2011; @LeeCK2013; @LeeCH2016; @KimHM2016; @Li2017; @KimSW2018; @ChoiYS2018; @MinJW2019; @KimHM2019; @SongHJ2019; @SongHJ2020; @YounJY2021; @ShinHJ2023].
This method either tags each syllable and then applies a base-form
restoration dictionary [@ShimKS2011; @LeeCH2016] or tags the syllable
with the base form already restored [@YounJY2021]. One notable drawback
is the challenge of accurately pinpointing morpheme boundaries.
Furthermore, as the sequences increase in length, the system finds it
increasingly challenging to understand long-term contextual data.

## Deep Learning and Tokenization {#subsec:deep-learning-and-tokenization}

The advent of deep learning has reshaped the Korean morphological
analysis landscape. High-performance deep learning models in NLP employ
tokenization, dividing the text into smaller units and then converting
these tokens into vectors as an input to the computational
model [@Mikolov2013]. The attempt to conduct subword tokenization,
incorporating separate morphemes to cater to Korean linguistic
characteristics is particularly significant. Incorporating accurate
morpheme analysis results into tokenization can improve overall analysis
performance.

With advancements in technology and access to large datasets, the
potential to integrate dictionary-based methods with deep learning
techniques has emerged. As motivated in our study, MeCab [@MeCab], an
open software for Korean and Japanese morphological analysis, utilized
dictionary-based morphological analysis trained by the CRF
method [@Lafferty2001]. This method attempts to find the optimal
morphological analysis path by forming a lattice structure as in
 [@Kudo2004; @NaSH2014; @NaSH2015; @NaSH2018]. The amalgamation of
dictionary-based methods with deep learning, as explored in our
research, signifies the latest strides in this journey aimed at
harnessing the strengths of both approaches. Future research avenues
include refining these hybrid methods and exploring the capabilities of
end-to-end models.

# Conclusion {#sec:conclusion}

This study signifies a progressive stride in Korean morphological
analysis by seamlessly merging conventional dictionary-based techniques
with advanced deep learning methodologies. Our findings indicate that
while relying solely on dictionary-based morphological analysis does not
surpass the efficacy of some existing models, the integration of a
BERT-based re-ranking system notably enhances accuracy, establishing a
new standard in this domain.

While the performance improvement increases computational demand, the
introduced methodology provides a promising avenue for continuous
enhancement. This innovative amalgamation of classical dictionary
approaches and cutting-edge machine-learning methodologies paves the way
for groundbreaking advancements in the intricate and multifaceted
domains of Korean linguistic processing.

Future endeavors in this domain should emphasize the refinement of this
harmonious integration to achieve even higher precision in morphological
analysis while optimizing computational efficiency. Moreover, our
observations indicate the potential for employing a probabilistic model
to discern areas where inaccuracies are likely to arise, thus enabling
the retrieval of more accurate interpretations from a narrower candidate
pool. The parallels between this initiative and the challenges of
translation quality estimation suggest that insights from the latter can
bolster the efficacy of our approach.
